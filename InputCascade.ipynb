{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InputCascade.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANGy3uRF79w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#required imports \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mlt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Activation, ZeroPadding2D, Lambda,Concatenate\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import h5py\n",
        "from keras.utils import layer_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnrdRaxpGFIp",
        "colab_type": "code",
        "outputId": "4b295887-b416-4999-fee6-cc233fa36ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#library for pre-processing mha files\n",
        "!pip3 install medpy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.2.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.18.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di5BAKGsGSbm",
        "colab_type": "code",
        "outputId": "5f34fcb5-18ae-4619-a295-448eee728bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k70kdz1kqjOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''A utility function for applying N4ITK bias correction to MRI slices'''\n",
        "\n",
        "import SimpleITK as sitk\n",
        "def preprocess(path):\n",
        "  #path='/content/gdrive/My Drive/BRATS2015_Training/HGG/brats_2013_pat0001_1/VSD.Brain.XX.O.MR_T1.54513/VSD.Brain.XX.O.MR_T1.54513.mha'\n",
        "  #path is the location of the .mha file. Modify it as per the files in your drive. \n",
        "\n",
        "  inputImage = sitk.ReadImage(path)\n",
        "  maskImage = sitk.OtsuThreshold( inputImage, 0, 1, 200 )\n",
        "  #Otsu thresholding sets the default mask\n",
        "\n",
        "  inputImage = sitk.Cast( inputImage, sitk.sitkFloat32 )\n",
        "  #Actual input image is of type int16, it has to be cast to Float32 \n",
        "  corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
        "  #corrector.SetMaximumNumberOfIterations( 1 ). It takes the default value for number of iterations.\n",
        "\n",
        "  output = corrector.Execute( inputImage, maskImage )\n",
        "\n",
        "  output_fn = path[:-4] + '_n.mha'\n",
        "  #Output normalised image is stored in the same folder as input with the input filename along with _n.mha\n",
        "  sitk.WriteImage( output, output_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuQXlMpsKilE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This function extracts 2d slices from each modality, converts them into numpy array and stacks them together\n",
        "Input: paths of four modalities\n",
        "Output: A list containing stacked axial 155 slices and the ground truth of these slices'''\n",
        "#imports required for pre-processing of the images\n",
        "from sklearn.preprocessing import normalize\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "from medpy.io import load, save\n",
        "#conversion of .mha files into n-dimensional numpy arrays\n",
        "def gen_image(path1, path2, path3,path4,gtpath):   \n",
        "  image_t1, image_header1 = load(path2)\n",
        "  image_t2, image_header2 =load(path4)\n",
        "  image_t1c, image_header1c =load(path3)\n",
        "  image_flair, image_headerr =load(path1)\n",
        "  image_gt, image_header_gt = load(gtpath)\n",
        "  t1x, t1y, t1z = image_t1.shape\n",
        "  final = np.zeros((155, 240, 240,4))\n",
        "#extraction of each slice of the four modalities and their normalization\n",
        "  for a in range(0, 155):\n",
        "    imgt1 = image_t1[:,:,a]\n",
        "    imgt1 = normalize(imgt1)\n",
        "    imgt2 = image_t2[:,:,a]\n",
        "    imgt2 = normalize(imgt2)\n",
        "    imgt1c = image_t1c[:,:,a]\n",
        "    imgt1c = normalize(imgt1c)\n",
        "    imgtflair = image_flair[:,:,a]\n",
        "    imgtflair = normalize(imgtflair)\n",
        " #for stacking of all 4 modalities together   \n",
        "    final[a] = np.dstack([imgt1, imgt2, imgt1c, imgtflair])\n",
        "\n",
        "  return final, image_gt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlAB1Q_eKpX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This function creates balanced input patches for each class\n",
        "Input: list of input patches and their groundtruth (gt)\n",
        "Output: Two lists of balanced input patches one sized 65x65x4 and other sized 33x33x4\n",
        "        List of middle pixel of ground truth with one hot encoding and integer labels\n",
        "        The number of pixels of each class '''\n",
        "def create_patch(array, gt):\n",
        "    patches65=[]\n",
        "    patches33=[]\n",
        "    \n",
        "    #gt_pixel = np.zeros(5580, dtype=int)\n",
        "    gt1=np.zeros((10000,1,1,5))\n",
        "    actual_gt=np.zeros(10000,dtype=int)\n",
        "    count0,count1,count2,count3,count4=0,0,0,0,0\n",
        "    k=0\n",
        "    #array of shape (155,240, 240,4). create patch of size (65, 65, 4) and (33, 33, 4) and check the labels of center pixel of gt\n",
        "    for slice in range(30,130):\n",
        "        c=30\n",
        "        for i in range(0,80):\n",
        "            r=30\n",
        "            for j in range(0,80):\n",
        "              \n",
        "                \n",
        "\n",
        "                key=gt[r+32,c+32,slice]\n",
        "                \n",
        "                actual_gt[k]=key\n",
        "                \n",
        "                \n",
        "                #gt_pixel[k]=gt[r+32:r+33,c+32:c+33,slice]\n",
        "                if(key==2 and count2<2000 ):\n",
        "                  patch=array[slice,r:r+65,c:c+65,:]\n",
        "                  s_patch=patch[16:49,16:49,:]\n",
        "                  patches65.append(patch)\n",
        "                  patches33.append(s_patch)\n",
        "                  gt1[k,0,0,key]=1\n",
        "                  k=k+1\n",
        "                  count2 = count2+1\n",
        "                if(key==1 and count1<2000 ):\n",
        "                  patch=array[slice,r:r+65,c:c+65,:]\n",
        "                  s_patch=patch[16:49,16:49,:]\n",
        "                  patches65.append(patch)\n",
        "                  patches33.append(s_patch)\n",
        "                  gt1[k,0,0,key]=1\n",
        "                  k=k+1\n",
        "                  count1 = count1+1\n",
        "                if(key==3 and count3<2000 ):\n",
        "                  patch=array[slice,r:r+65,c:c+65,:]\n",
        "                  s_patch=patch[16:49,16:49,:]\n",
        "                  patches65.append(patch)\n",
        "                  patches33.append(s_patch)\n",
        "                  gt1[k,0,0,key]=1\n",
        "                  k=k+1\n",
        "                  count3 = count3+1\n",
        "                if(key==4 and count4<2000 ):\n",
        "                  patch=array[slice,r:r+65,c:c+65,:]\n",
        "                  s_patch=patch[16:49,16:49,:]\n",
        "                  patches65.append(patch)\n",
        "                  patches33.append(s_patch)\n",
        "                  gt1[k,0,0,key]=1\n",
        "                  k=k+1\n",
        "                  count4 = count4+1\n",
        "                r=r+2\n",
        "            c=c+2\n",
        "    for slice in range(50,130):\n",
        "        l=30\n",
        "        for i in range(0,6):\n",
        "            m=30\n",
        "            for j in range(0,6):\n",
        "              key=gt[l+32,m+32,slice]\n",
        "              if(k==8000 or count0==1999):\n",
        "                gt2 = gt1[0:k]\n",
        "                return patches65, patches33, gt2, actual_gt,count0,count2,count3,count4\n",
        "              actual_gt[k]=key\n",
        "\n",
        "              if(key==0 and count0<2000 ):\n",
        "                patch=array[slice,l:l+65,m:m+65,:]\n",
        "                s_patch=patch[16:49,16:49,:]\n",
        "                patches65.append(patch)\n",
        "                patches33.append(s_patch)\n",
        "                gt1[k,0,0,key]=1\n",
        "                k=k+1\n",
        "                count0 = count0+1\n",
        "              m=m+20\n",
        "            l=l+20\n",
        "    gt2 = gt1[0:k]\n",
        "    \n",
        "    return patches65, patches33, gt2, actual_gt, count0,count2,count3,count4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9shhgNXVKuIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This CNN mplements the two way CNN architecture\n",
        "Input: input patch in form of tensor\n",
        "Output: an output patch(dimension depends on the input)'''\n",
        "def two_way_CNN(img):\n",
        "  \n",
        "    #valid padding means no padding, stride is 1 by default\n",
        "    #the local pathway\n",
        "    O1 = Conv2D(filters= 64,kernel_size =(7,7),strides=(1,1),padding='valid')(img)\n",
        "    O2 = Conv2D(filters= 64,kernel_size =(7,7),strides=(1,1),padding='valid')(img)\n",
        "  \n",
        "    Max_O = keras.layers.Maximum()([O1,O2])\n",
        "    Max_O = MaxPooling2D(pool_size=(4,4), padding='valid',strides=(1,1), data_format='channels_last')(Max_O)\n",
        "    \n",
        "  \n",
        "    #Coming to the second layer ...\n",
        "    O3 = Conv2D(filters= 64,kernel_size =(3,3),strides=(1,1),padding='valid')(Max_O)\n",
        "    O4 = Conv2D(filters= 64,kernel_size =(3,3),strides=(1,1),padding='valid')(Max_O)\n",
        "    Max_O = keras.layers.Maximum()([O3,O4])\n",
        "    Max_O = MaxPooling2D(pool_size=(2,2),padding='valid',strides=(1,1),data_format='channels_last')(Max_O)\n",
        "    \n",
        "    #for the second path(global).. no pooling here\n",
        "    O5=Conv2D(filters= 160,kernel_size =(13,13),strides=(1,1),padding='valid')(img)\n",
        "    O6=Conv2D(filters= 160,kernel_size =(13,13),strides=(1,1),padding='valid')(img)\n",
        "    \n",
        "    Max_O3 = keras.layers.Maximum()([O5,O6])\n",
        "    \n",
        "    # concatenation of two pathways\n",
        "    Max_O4 = Concatenate()([Max_O,Max_O3])\n",
        "    #our final output...\n",
        "    \n",
        "    Max_O5 = Conv2D(filters=5,kernel_size=(21,21),strides=(1,1), padding ='valid', activation = 'softmax',kernel_regularizer=regularizers.l1_l2(0.01,0.01))(Max_O4)\n",
        "    return Max_O5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34tS4tQ3K1wG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Implements the input Cascade CNN architecture\n",
        "Input: None\n",
        "Output: an instance of model class implemeting the Input Cascade CNN architecture'''\n",
        "def inputCascadeCNN():\n",
        "  \n",
        "    img1 = Input((65,65,4))\n",
        "  \n",
        "    O1 = two_way_CNN(img1)   \n",
        "    # the output of first CNN\n",
        "  \n",
        "    img2 = Input((33,33,4))    \n",
        "    O2 = Concatenate()([O1,img2])\n",
        "    # Concatenated input is fed into the second CNN to give the output one-hot encoded.\n",
        "  \n",
        "    O2 = two_way_CNN(O2)\n",
        "    final_model = Model(inputs = [img1, img2], outputs = O2 )\n",
        "    return final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJidaqLlK5Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utility function for calculating the dice score\n",
        "def dice_score(y_true, y_pred):\n",
        "    y_true_f = K.batch_flatten(y_true)\n",
        "    y_pred_f = K.batch_flatten(y_pred)\n",
        "    intersection = 2. * K.sum(y_true_f * y_pred_f, axis=1, keepdims=True) + smooth\n",
        "    union = K.sum(y_true_f, axis=1, keepdims=True) + K.sum(y_pred_f, axis=1, keepdims=True) + smooth\n",
        "    return K.mean(intersection / union)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZJEhGTPM_ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = inputCascadeCNN()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_jFWsZuK-Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This cell trains the CNN with a balanced dataset. Change the variable path as per the requirement'''\n",
        "from sklearn.utils import class_weight\n",
        "from keras import backend as K\n",
        "smooth=1\n",
        "#path = '/content/gdrive/My Drive/NNFL Assignment/BRATS 2015 Dataset/Training'\n",
        "path='/content/gdrive/My Drive/NNFL/DATASET/BRATS2015_Training'\n",
        "#path='/content/gdrive/My Drive/BRATS2015_Training'\n",
        "j=0\n",
        "model=inputCascadeCNN()\n",
        "with os.scandir(path) as training:\n",
        "    for folder1 in training:\n",
        "        path1 = path + '//' + folder1.name\n",
        "        with os.scandir(path1) as lgg_hgg:\n",
        "            for folder2 in lgg_hgg:\n",
        "                path2 = path1 + '//' + folder2.name\n",
        "                with os.scandir(path2) as brats:\n",
        "                    modularity_path = []\n",
        "                    for folder3 in brats:          \n",
        "                        path3 = path2 + '/' + folder3.name\n",
        "                        with os.scandir(path3) as vsdbrain:\n",
        "                            for file in vsdbrain:\n",
        "                                if file.name.endswith('mha'):\n",
        "                                    path4 = path3 + '/' + file.name\n",
        "                                    modularity_path.append(path4)      \n",
        "                \n",
        "                sorted_path = sorted(modularity_path)\n",
        "                print(sorted_path)\n",
        "                #for preventing array out of bounds error\n",
        "                try:\n",
        "                  arr, gt= gen_image(sorted_path[0], sorted_path[1], sorted_path[2], sorted_path[3], sorted_path[4])\n",
        "                  patches65, patches33, gt_pixel, actual_gt, a,b,c,d = create_patch(arr, gt)\n",
        "                  print(a,b,c,d)\n",
        "                  \n",
        "                  #to account for minor disbalance in the data.\n",
        "                  #class_weight: useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
        "                  \n",
        "                  class_weights = class_weight.compute_class_weight('balanced',np.unique(actual_gt),actual_gt)\n",
        "                  class_weights = class_weights[1:]\n",
        "                  #for regular saving of the model\n",
        "                  if(j==20 or j==80 or j==120 or j==150 or j==200 or j==250):\n",
        "                    model_json = model.to_json()\n",
        "                    with open(\"/content/gdrive/My Drive/mymodelinput.json\",\"w\") as json_file:\n",
        "                      json_file.write(model_json)\n",
        "                    model.save_weights(\"/content/gdrive/My Drive/myinputweight274.h5\")\n",
        "                    print(\"Saved model to disk\")\n",
        "\n",
        "                  #compiling and fiting the model                      \n",
        "                  sgd = keras.optimizers.SGD(learning_rate=0.005, momentum=0.5, nesterov=False)\n",
        "                  model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy',tf.keras.metrics.Precision(class_id=0, name = 'normal_tissue_precision'),tf.keras.metrics.Precision(class_id=2,name = 'edema_precision'),tf.keras.metrics.Precision(class_id=3,name = 'non_enhancing_tumor_precision'),tf.keras.metrics.Precision(class_id=4,name = 'enhancing_tumor_precision'),tf.keras.metrics.Recall(class_id=0,name = 'normal_tissue_recall'),tf.keras.metrics.Recall(class_id=2,name = 'edema_recall'),tf.keras.metrics.Recall(class_id=3,name = 'non_enhancing_tumor_recall'),tf.keras.metrics.Recall(class_id=4,name = 'enhancing_tumor_recall')])\n",
        "                  model.fit([patches65, patches33],gt_pixel,epochs=1, class_weight=class_weights)\n",
        "                  j=j+1\n",
        "                  print(j)\n",
        "                except:\n",
        "                  print(j)\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iue_qSe_46f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model results\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/mymodelinput.json\",\"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"/content/gdrive/My Drive/myinputweight274.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITV8aTd4M5rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('/content/gdrive/My Drive/mymodelmodel.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"/content/gdrive/My Drive/myinputweight274.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}